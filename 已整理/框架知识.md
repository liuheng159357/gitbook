##spring
	spring core
		BeanFactory
		创建，装配，销毁bean
		ioc
			获得依赖对象的方式反转了
			一个对象依赖的其它对象会通过被动的方式传递进来
			1.读取配置 2.创建组装 3.从容器获取
			接口，set，构造器
			scope: 单例、多例、request、session、applciation
			scope,lazy,depends-on,init-method,destroy-method
			@Component@Repository@Service@Constroller
			@Qualifier@autowired@resource
			反射
				运行时创建对象
				获取Class的三种方式
				根据class获取类的类名，属性，方法，构造函数，注解，父类，子类
				根据class创建对象-无参构造函数
				增强程序灵活性，避免写死
				ASM字节码
	spring context
		ApplicationContext 实现BeanFactory所有功能，并添加了事件处理，国际化，资源文件处理等企业服务
	spring aop
		静态代理
			编译时生成代理类，一个被代理类对应一个代理类
		动态代理
			运行时动态生成，一个代理类可以代理所有
			继承InvocationHandler接口，实现invoke方法
			调用Proxy.newProxyInstance，传入被代理类接口和InvocationHandler
			通过反射创建代理类
				1.获取代理类的所有方法
				2.覆盖代理类接口中的方法，调用InvocationHandler的invoke
		jdk与cglib
			接口
			抽象类
		spring
			切面
			增强
				前置、后置、环绕、返回、异常
			切点
			连接点
	spring mvc

##spring boot
	启动原理
		EnableAutoConfiguration
		spring.factories
		@Conditional
		找到自动配置文件：自动扫描 | @EnableXXX
		默认大于配置
	注解
		@Enable注解：开启指定功能
		@ConfigurationProperties@value：属性映射
		@Conditional：条件注解
		@ComponentScan：默认扫描启动类所在包
		@configuration@bean
		@Import@ImportResource
		@SpringBootApplication
		@Profile:环境隔离
		@EnableConfigureProperty
	mvc
		监听器
		拦截器
		全局异常
		异步任务
		mvc配置
			继承WebMvcConfigurerAdapter -- 配置拦截器、类型转换器、视图解析
			继承WebApplicationInitializer -- 代替web.xml 配置servlet，过滤器，监听器
	组件
		数据访问
		缓存
		消息
		调度
	其他
		测试
		监控
		热部署

##spring cloud
	Spring Boot专注个体服务
	Spring Cloud关注全局的服务治理
	zuui 网关
	config 配置中心
		server
			存储配置：git|svn|本地
			多文件环境隔离
			通过接口提供配置
			@EnableConfigServer
		client
			spring.cloud.config.name=neo-config
			spring.cloud.config.profile=dev
			spring.cloud.config.uri=http://localhost:8001/
			spring.cloud.config.label=master
			服务化：
				spring.cloud.config.discovery.enabled=true
				spring.cloud.config.discovery.serviceId=spring-cloud-config-server
			refresh机制
				1.添加actuator依赖 关闭安全验证management.security.enabled=false
				2.@RefreshScope添加在需要refresh的变量所在类
				3.访问http://XXX/refresh (webhook自动触发)
	eureka 注册中心
		c-s架构
		心跳连接
		服务提供方、消费方
		互相注册实现高可用
		@EnableEurekaServer@EnableEurekaClient
		eureka.client.serviceUrl.defaultZone
	bus 消息总线
		AMQP
		广播状态的变化（例如配置变化）
		应用场景：配置中心客户端刷新
	feign 服务调用
		@EnableFeignClients
		@FeignClient
		ribbon 负载均衡
		hystrix 熔断器
			熔断：失败数达到一定数量，切换开关，一定时间后判断服务正常后，切换开关
			降级：实现fallback方法，服务异常时调用
			feign.hystrix.enabled=true
			监控面板
				Hystrix Dashboard
				Turbine：分布式中聚合多个节点展示
	sleuth 分布式服务跟踪


##kafka
	zookeeper作用
		broker动态加入和离开 
			topics
			partitions
		consumer动态加入和离开
			订阅的topic
			指定的group
		维护consumer与partition的负载均衡
		维护消费关系以及offset
		leader选举
	基本架构
		broker
			controller
				在ZooKeeper注册Watch
				与zookeeper交互
				leader 选举
				failover
		topic
			创建
			删除
		partition
			replica
				副本，保证分区高可用
				分配算法，不得大于broker数
			leader partition
				leader选举产生
				leader所在broker宕机后,zookeeper会重新选举
				与生产消费者交互
			follower partition
				leader接受消息后同步到follower	
		ISR
			leader记录的与其保持同步的replica列表
			移除条件
				数据落后太多
				超过一定时间未响应
			leader partition挂掉会从ISR中选举leader
		group
			被group的一个consumer消费,能被多个group消费
			group下 线程数=partition数量 效率最高
			group下的consumer并行消费不同的partition
		segment
			分区中消息存储单位
			当消息数量达到配置值或发布时间超过阈值，segment会flush到磁盘
			当segment达到一定数量后创建新的segment
			组成
				.index 
				.log
				文件名 - 前文件最后一条消息id+1
	生产者
		发消息
			1.Metadata 协议获取topic的partition列表，每个partition leader所在broker
			2.负载均衡获取partition
				hash 轮询
			3.给partition leader所在broker发消息
		消费可靠性
			at most once
			at least once 默认
			exactly once
		确认模式
			ack=0 发送即成功
			ack=1 leader接受即成功
			ack=-1 全部follower接受才成功
		批量发送
			减少网络请求和磁盘IO
	消费者
		group，topic，多线程，pull机制
		offset
			high-level --> zookeeper
			low-level --> 自己维护
		消费可靠性
			at most once
			at least once 默认
			exactly once
			先commit再处理消息
	message
		有序 持久化 有效期
		消息不会立即同步磁盘，暂存buffer，达到阈值，flush到磁盘
		以追加的方式顺序写入磁盘，消费时从磁盘读取
	特点
		分布式
		吞吐量
		持久化
		容错性
	高性能
		读消息-零拷贝
			省去两次复制
			读取文件：读到内核-复制到用户空间-复制到socket内核空间
			零拷贝：建立内存与磁盘的映射，数据直接从DMA内核到socket内核
		写消息-顺序写磁盘
			省去机械耗时
		批量压缩
	服务器配置
		参数
		优化
	问题
		重复消费问题
			幂等性处理
		消息丢失
			消费者commit后处理消息失败，人工补偿
		保证消息有序问题
			kafka只能保证单个partition的有序性
			可通过指定分区发送和消费保证整体有序
		对比其他消息中间件
			吞吐量
			事务性
			同步 异步
			push pull
			消息有效期

##zookeeper
	分布式协调服务-监视集群节点状态
	基本架构
		文件系统
			多层级节点命名空间
			文件节点-关联数据-1M
			znode
				持久化 持久化有序 临时 临时有序
				临时节点不能创建子节点
				临时节点移除 -- SESSIONEXPIRED
		watch机制
			znode变化,通知client
			一次性触发,需重复注册
			数据版本
			注册watch
				数据watch  getData()和exists()
				子节点watch  getChildren()
			触发watch
				create、delete、setData
	核心	
		原子广播（zab协议）
			恢复模式
				选主 
					fast paxos算法
					全新
						server id大的胜出
					非全新
						version、serverid 和逻辑时钟
						1、逻辑时钟小的选举结果被忽略，重新投票
				　　　　2、统一逻辑时钟后，数据 version 大的胜出
				　　　　3、数据 version 相同的情况下，server id 大的胜出
				数据同步
					根据zxid(递增的事务id)确定同步点
				三种情况
					启动
					ping follower没超过一半
					leader 挂掉
			广播模式
				数据一致性 
				两阶段提交
				事务发起 -- 集群follower -- 投票超半数 -- commit
		server状态
			leading  --- 当前为leader
			following --- 同步状态
			looking --- 寻找leader
		有序性
			zxid
				低32位-递增计数器
				高32位-epoch 区分leader周期
			读数据-其中一台server
			写数据
				follower接受请求转发给leader
				leader接受请求广播所有server		
		集群机制
			超过半数的节点正常则正常服务
			follower
			1.PING消息： 心跳消息；
		　　2.PROPOSAL消息：Leader发起的提案，要求Follower投票；
		　　3.COMMIT消息：服务器端最新一次提案的信息；
		　　4.UPTODATE消息：表明同步完成；
		　　5.REVALIDATE消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；
		　　6.SYNC消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。
	应用
		注册中心 -- dubbo
			服务名对应节点，节点数据即为服务的ip和port
		集群管理 -- kafka
			监控服务器状态
			master选举
			实现：
				服务器加入，父节点下创建临时有序节点，设置watch
				服务器故障，节点自动删除
				节点id最小即为master
		动态配置
			创建节点绑定数据，注册数据watch
		分布式锁
			父节点下创建临时有序节点，注册watch，id最小的获得锁
	问题
		为什么需要leader ---- 一台机器执行，共享结果，避免重复计算
		zookeeper应用

##redis
	核心
		数据类型
			string 
				int - shared常量池
				raw
				包含任何数据，图片，序列化对象，字符串
			hash 
				数组-小数据量-默认64
				hashmap-大数据量
				存储对象
					id->{
						field:value
					}
					id+field操作属性数据,无需操作整个对象
			list 双向链表
			set 去重，value=null的hashmap 
			zset 
				score hashMap 跳跃表 排序
		内存模型
			key-value
				实现同hashmap，都是数组+链表方式，entry对象（key value next）
			数据结构抽象
				redisObject
					type encoding lru ptr指针
			虚拟内存
				会把不常用键的值放到磁盘
				内存与磁盘swap，影响性能
			淘汰策略
				内存使用完毕，再次申请内存
			 	1.拒绝处理，报错(默认)
				2.主键或有过期时间主键，移除key(LRU最近未使用,随机,失效时间近)
			过期策略
				1.给每一个key设置timer
				2.定期删除
					定期扫描一定数量设置了过期时间的key，然后清除
				3.惰性过期
					get时判断过期删除
		网络模型
			io多路复用
			单线程
			epoll
		持久化
			快照
				定时任务-是否达到触发条件-次数/时间
				fork子进程-共享内存空间-遍历写到RDB文件
				copy-on-write
				缺点：
					丢失上次快照与重启之间所有的数据
					Buffer IO问题：快照文件读写时操作系统会有cache，重复存储
			aof
				数据改变追加到log文件，重启读取文件执行一遍
				缺点：
					log过大，恢复时间长
					每次改变都要写log
		事务
			一次执行多个命令
			1.原子性
				全部成功或全部失败
			2.隔离性
				序列化 顺序执行 不可打断
			MULTI 、 EXEC 、 DISCARD 和 WATCH
			事务提交前，不会执行任何指令，只会把它们存到一个队列
			CAS
		Pipelining
			客户端一次发送多个命令 顺序执行
	集群
		三种技术
			replication
				避免单机故障
				原理
					slave启动-发送sync到master-master生成rdb和命令缓存同步给slave-后面命令逐个同步的(异步)
					slave断开重连-增量复制
				2.8后可选无硬盘复制
			sentinel
				哨兵机制-监控+故障转移
				1.心跳监测
				2.选举master，并重新设置slave的master
				3.等待老master恢复并设为slave
			sharding
		两种方案
			主从+哨兵
				一主多从+故障转移
				写主读随机
				节点存全量数据，node压力大
			分片+主从
				数据多节点分布存储
				hash读写node
				主从保证单node高可用，支持故障重新选举
				节点存部分数据，node压力小，多服务器
				分片实现
					客户端分片
						优点：服务器独立，实现简单
						缺点: 无法动态扩容，额外维护HA以及监控节点状态
					代理分片
						Twemproxy
						路由透明，节点自动删除
					服务器分片
						Redis Cluster
						优点：支持HA 动态扩容 节点状态同步
						原理
							hash槽
								key的空间被分到16384个hash slot里
								计算key属于哪个slot
								每个节点负责一定数量的槽
							扩容
								迁移槽和数据
	优化
		设置最大内存 - 避免使用虚拟内存 - 避免频繁swap
		关闭vm
		适当选择或关闭持久化方式
		选择合适数据类型
			设置常量池
			设置hash存储结构
		不要超过3/5
	高性能
		即使单线程也很快的原因 
			10w+QPS
			1.减少线程切换，不用考虑锁
			2.纯内存操作
			3.epoll 多路复用
			4.数据结构设计
			5.纯c语言编写
		单线程缺点：
			耗时请求会阻塞
			不能有效利用多核
	问题
		先更新缓存还是数据库
		Memcache与Redis的区别都有哪些
		持久化方式为啥不rdb和aof结合使用
		分布式锁实现
			SETNX 当key不存在，set成功返回1 单线程顺序执行
		keys会阻塞，代替keys方法
			scan 无阻塞 有重复
		异步队列
			list结构作为队列，rpush生产消息，lpop消费消息 blpop消费时会阻塞直到消息到来
			pub/sub实现1-n 消费者下线消息会丢失
			延时队列 使用sortedset 时间戳排序
		大量key设置相同过期时间
			在时间上加一个随机值 防止卡顿


##mysql
	索引
		基础
			加速查询-避免扫描全表
			顺序查找较慢，合适的数据结构能快速定位数据
		索引文件
			索引较大，以文件的形式存储，检索文件需要磁盘io
			设计的数据结构要尽可能减少磁盘io
		数据结构
			存储器原理
				内存随机读写，数据的距离不影响读取速度
				磁盘
					寻道
					磁盘旋转
					局部性原理
						当一个数据被用到时，其附近的数据也通常会马上被使用
					磁盘预读
						顺序读取 很少的旋转时间
						以页为单位预读
					缺页异常
						主存和磁盘以页为单位交换数据
						数据不在主存触发缺页异常
			二叉搜索树
				节点度为2
				左节点小于父节点，右节点大于父节点
			b-tree
				节点度>=2
				节点由key和指针相互间隔，key的值从左往右递增，指针数量比key多1个
				所有叶节点都在同一层
				指针指向子节点所有key要大于指针左节点，小于指针又节点
				查找算法：
					节点key采用二分法查找，命中返回，否则向下递归
			b+tree
				与b-tree区别
					1.节点指针数=节点key
					2.内节点只有指针和key，叶节点只有数据和key
				带有顺序指针的b+tree
					节点之间顺序指针连接
					查询连续记录时，效率更高
			二叉树&b-tree
				h为树的高度
				检索一次最多访问h个节点
				根据磁盘预读原理将节点大小设为一个页，故磁盘io次数为h
				二叉树的度为2，h一般较大
				b-tree的度一般较大，h较小
			b-tree&b+tree
				h越小性能越好，而d越大h越小
				d=page/(指针+key+data)
				b+tree内节点没有data，使得节点的度变大，性能更好
			hash&b-tree
				hash搜索单条记录快
				b-tree搜索多条记录快
		索引实现
			MyISAM
				主键索引与辅助索引没啥区别，都是非聚集索引
			InnoDB
				主键索引
					聚集索引
					默认生成，主键为索引的key（innodb表一定要有主键的原因）
				辅助索引
					data保存的是主键值
					辅助索引查找数据，要检索本身和主键索引
			聚集与非聚集
				聚集索引-data保存完整的数据记录
				非聚集索引-data存放的地址
		索引分类
			普通索引：加速查找
			主键索引：加速查找+非空唯一约束
			唯一索引：加速查找+唯一约束
			组合索引：多列组合，key为组合最左列，data含有组合的全部列	
			全文索引：搜索大数据字段
		索引优化
			最左原则
				组合索引从最左边字段向右匹配直到遇到范围查询(>、<、between、like)就停止匹配
				若where字段没有组合的最左字段，无法使用索引搜索，只能扫码索引文件
				字段的查询顺序不影响，查询优化器会优化成组合索引顺序
			前缀索引
				用列的前缀代替整个列，使data变小
			覆盖索引
				直接从索引数据中返回结果，不访问表文件
				需要指定查询字段，多条件查询必须覆盖组合索引全部字段
			主键连续
				插入时顺序添加到节点的后续位置，否则会随机插入页的任意位置，打乱索引结构，导致频繁移动
			索引排序
			组合代替多个单列索引
		索引使用
			缺点
				占用存储空间，插入修改删除维护
			不适用
				1.表记录少
				2.唯一性差
				3.频繁更新的字段
			索引失效
				1.组合索引最左原则
				2函数，表达式
				3.左模糊 
				4.普通索引的!=
				5.or - 除非or的列都有索引
				6.字符串 - 使用引号
				7.is null

	事务
		ACID
			原子性：要么成功要么失败
			一致性：一种状态转化到另一种状态
			隔离性：事务之间不会相互影响
			持久性：一旦提交，数据永久保存
			实现
				锁实现隔离性
				日志实现原子性，一致性，持久性
		隔离&锁
			并发问题
				脏读 - 读到事务未提交的数据
				不可重复读 - 两次读取的数据不同（修改）
				幻读 - 两次读取的数据记录不同（添加，删除）
			隔离级别
				读未提交 - 啥问题都会出现
				读已提交 - 解决脏读
				可重复读 - 解决不可重复读（默认），特殊情况下会出现幻读
				串行 - 全部解决
			锁
				mvcc 
					多版本并发控制器,读非阻塞
					原理
						隐藏列-创建时间,删除时间
						select:create<当前事务id&delete>当前事务id
						insert:create为当前事务id
						delete:delete为当前事务id
						update
							新建一条记录create为当前事务id，原来记录delete为当前事务id
							定时清理无效记录-purge
				悲观锁
					粒度
						表锁 - 开销小，并发性能低
						行锁 - 开销大，并发性能高
					类型
						共享锁（读锁）
						排它锁（写锁）
						意向锁
				间隙锁
			实现
				快照读
					普通查询使用
					快照
						时间点
							RC-事务中每个select都会生成快照
							RR-事务的第一个select生成快照
						内容
							read_view对象
								活跃的事务id集合
								最小事务id
								即将分配的事务id
							根据算法导出逻辑内容为生成点之前所有提交了的数据
					解决脏读，重复读，幻读：mvcc
				当前读
					增删改以及特殊查询使用
					读到最新数据
					解决幻读：行锁+gap锁=next key锁
				读未提交
					不加锁
				RC
					mvcc+行锁
				RR
					mvcc+next-key
				串行
					基于悲观锁
	日志
		错误日志
			启动运行关闭过程中的错误信息
		查询日志
			普通select sql
		慢日志
			执行超过一定时间的sql
		二进制日志
			记录增删改，备份和还原
		中继日志
			从主服务器binlog复制的事件，保存为新的binlog
		事务日志
			保证事务原子性，持久性
			数据与日志
				data_buffer data_file
				log_buffer log_file
			原子性
				undo log - 修改前的数据备份 - 逻辑日志 - 对行进行记录
				回滚原理：
					可以认为当delete一条记录时，undo log中会记录一条对应的insert记录
					反之亦然，当update一条记录时，它记录一条对应相反的update记录
			持久性
				背景：
					为减少磁盘io，数据存在内存缓冲区，先操作缓冲区再同步磁盘
					当缓冲区操作成功返回成功后，系统崩溃重启，磁盘数据无法恢复到最新
				redo log - 修改后的数据备份 - 物理日志 - 数据页的记录
			事务过程
				1.写undo log 到log_buffer
				2.修改data buffer
				3.写redo log 到log_buffer
				4.redo log刷盘到log_file
				5.commit
			日志刷盘
				red buffer同步到log_file,又引入了新的磁盘io
				规则
					1.innodb_flush_log_at_trx_commit 控制
						1.每次提交前写os buffer且同步磁盘
						2.每隔1秒将log buffer写os buffer且同步磁盘
						3.提交写os buffer，每隔1秒同步磁盘
					2.log buffer内存过半
					3.触发checkpoint
				优化
					redo log存储在连续的空间，系统启动完全分配，日志顺序追加
					批量写
					并发事务共享redo log 空间
			数据刷盘
				checkpoint : 将脏数据和脏日志同步到磁盘,减少数据恢复时间,保证buffer可用
				1.sharp checkpoint
					一次性刷盘
				2.fuzzy checkpoint
					部分刷盘
					触发时间
						1.线程控制，秒级定时触发
						2.LRU列表，可用页少于最小空闲页时
						3.redo log不可用时
						4.脏页达到一定数量时
					LSN
						创建阶段：事务创建一条日志 LSN1
						日志刷盘：日志写入到磁盘上的日志文件 LSN2
						数据刷盘：日志对应的脏页数据写入到磁盘上的数据文件 LSN3
						写CKP：日志被当作Checkpoint写入日志文件 LSN4
			启动恢复
	存储引擎
		InnoDB
			支持事务，支持mvcc
			支持行级锁
			聚集索引
			支持外键
			不支持全文索引
		MyISAM
			非事务
			表级锁
			非聚集索引
			支持全文索引
		场景
			MyISAM
				(1)做很多count 的计算；
				(2)插入不频繁，查询非常频繁；
				(3)没有事务。
			InnoDB
				(1)可靠性要求比较高，或者要求事务；
				(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况。
	主从复制
		用途
			读写分离
			冗余备份
		原理
			1.io线程
				监听master二进制文件变化
				保存为中继日志
			2.sql线程
				执行中继日志中的事件 
		问题
			1.数据丢失 - 半同步复制 - 写完binlog后需要从库ack应答
			2.复制延时 - 并行复制 - 库级别多线程监听binlog
		实现
			MySQLProxy中间件
			客户端-服务器中间，建立连接池，读写自动切换且负载均衡
	集群
		高可用
			vip+keepalived+heartbeat+haproxy
			MHA MMM
			MySQL Galera
			MySQL cluster
		分表分库
			mycat
	性能分析&故障排查&优化
		优化
			sql优化
				避免select *,多用limit top
				order by 使用索引,避免表达式
				where替换having,exists替代distinct
				exists替代in,not exists替代not in
				where条件从右到左，能过滤大部分数据的条件放在最右
				连接查询,小数据集驱动大数据集
				使用临时表
				建立索引,避免索引失效
			表优化
				1.索引
				2.数据类型
					更小 更简单 避免null
					1.整数
						UNSIGNED存储非负
						不必指定长度
						tinyint代替enum
					2.实数 
						BIGINT代替DECIMAL
					3.字符串
						指定长度
						char代替varchar
					4.时间
						date - 只存储日志
						datetime - 存储时分秒，范围大，8字节
						timestamp - 存储时分秒，范围小，4字节
						使用时间戳代替
				3.表结构
					三范式
					反范式
			服务器优化
		性能分析
			慢日志
				默认不开启
				分析工具mysqldumpslow
			explain
				select_type
					simple primary subquery derived
				type
					system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL
				possible_keys
				key
				key_len
				rows
				Extra
					Using index Using where Using temporary
	未完成
		命令 工具
		函数
		系统变量
		启动参数
		系统数据库
		备份 权限 授权 用户
		表设计
		性能优化 性能分析 监控 故障排查
		存储引擎
		缓存
		集群 主从 分片