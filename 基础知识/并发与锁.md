##并发与锁
	基本概念
		多线程-并发-临界资源-同步-死锁
		sleep，yield，join,wait,interrupt
		wait、notify、notifyAll、Condition
		上下文切换，临界区，守护与用户线程，死锁
	内存模型
		内存-高速缓存-cpu
		主内存-工作内存-线程
		工作内存中保存了主内存共享变量的副本
		8个原子性操作：lock,unlock，read，load，use,assign,store，write
		**synchronized保证原子性，可见性，有序性（串行相当于单线程）**
		**volatile保证了可见性，有序性（Happens-before原则）**
		原子性
			一个不可中断的操作
			操作系统
				单核：主内存与工作内存之间的8个操作原子性，使得基本数据类型读写不可中断（有些jvm不保证64位）
				多核：总线锁定，缓存锁定，缓存一致性协议
			java: 锁（synchronized）
		可见性
			修改后的数据对所有线程立即可见
			volatile
				保证能看见其他线程对变量的修改
					read、load、use操作，须连续一起出现，每次use时，都从主内存read，工作内存load主内存的值
				保证其他线程可以看到自己对变量的修改
					assign、store、write操作，须连续一起出现，工作内存中的每次修改，须立刻同步回主内存
			synchronized：串行后线程读取的都是变量的最新值
		有序性
			指令重排：
				为了优化性能(最大化利用缓存)，编译器的默认行为（编译器重排序和运行时重排序）
				依据：as-if-serial，程序的结果不变，故重排序不会发生在有数据依赖的操作之中
			单线程：
				所有操作都是有序的
				单线程下，虽然指令重排，但结果一样，故单线程始终有序
			多线程：
				发生指令重排后，可能会影响程序预期结果
				只有禁止重排，才能保证有序性
				禁止重排原则：Happens-before（8个规定，包含volatile,当符合该8个规定时，指令不会重排）
				案例：双重check的单例模式
					 instance = new Singleton();  //非原子操作
					 memory =allocate();    //1：分配对象的内存空间 
					 ctorInstance(memory);  //2：初始化对象 
					 instance =memory;     //3：设置instance指向刚分配的内存地址
					 重排后可能为1,3,2 多线程下获取到的instance可能为空，即未初始化
					 解决办法：private volatile static Singleton instance = null;
		内存屏障/栅栏
			一种CPU指令，用于控制特定条件下的重排序和内存可见性问题
			相关指令
				read/write
				load/store
			栅栏：粗粒度，栅栏前的load,store指令一定在栅栏后的load,store指令之前执行,开销大
			屏障：细粒度
				StoreStore
				LoadStore
				StoreLoad
				LoadLoad
		伪共享
		合并写
		管程
	同步方法（原理，应用）
		synchronized
			lock,unlock
			monitorenter,monitorexit	
		JUC
			ReetrantLock
			Atomics
		ThreadLocal
	锁优化
		时间-减少持有时间
		粒度-减少锁的范围
		类型-读写代替独占
		无锁，偏向锁，轻量锁，重量锁
	JUC底层
		CAS
			旧的预期值A，当前内存值V、即将更新的值B
			Unsafe
				valueOffset-获取变量的偏移地址，从而获取内存中的值
				compareAndSwapInt
					原子操作
					本地方法
					靠缓存锁定保证多核下的原子性
					比较预期值和当前内存值，相同则修改，返回true---否则轮训获取最新内存值继续调用compareAndSwapInt直到成功
			volatile：保证变量可见性,轮训时时获取最新值
			缺点
				循环时间长-可限制自旋次数
				只保证一个共享变量原子操作
				ABA问题-加版本解决
		AQS
			state状态 
				volatile
				cas获取同步状态
			同步队列
				双向链表
					node(pre next)
					头结点-当前获取到同步状态的结点
					尾节点
				自旋CAS-将获取同步状态失败的线程封装成节点添加到队列尾部，保证线程安全
				内部死循环获取同步状态(只有老二节点有资格)-成功或阻塞
				线程排队,阻塞,唤醒
			获取状态
				获取失败后加入队列阻塞等待唤醒
			释放状态
				释放成功后唤醒next节点线程
			独占 共享
			tryAcquire tryAcquireShared tryRelease tryReleaseShared
	JUC实现
		LOCK
			独占锁 读写锁
		原子类
			AtomicStampedReference
		阻塞队列
		并发容器
		线程池
		并发工具类
			CountDownLatch
				线程之间的等待，控制线程在其他线程组执行任务后才能执行
			CyclicBarrier
				线程组内的相互等待，所有线程执行到一定状态后才能往下执行
			Semaphore
				信号量，控制线程并发的数量
			异步编程/线程编排 Callable、Future、FutureTask、CompletableFuture
			并行计算 fork/join


================================线程池
http://www.oschina.net/question/565065_86540?fromerr=q6YijfBS
为什么需要线程池
1.减少创建和销毁线程时间，重复利用
2.控制线程数量，防止内存崩掉

结构
1.Executor 顶级接口，线程工具
2.ExecutorService、ScheduledExecutorService 线程池接口
3.ThreadPoolExecutor、ScheduledThreadPoolExecutor 对应的线程池接口实现
4.Executors:线程池的静态工厂,创建的线程池都是基于ThreadPoolExecutor

工厂中存在的线程池
1. newSingleThreadExecutor
    创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。
2.newFixedThreadPool
    创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。
3. newCachedThreadPool
    创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，
    那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。
4.newScheduledThreadPool
    创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。

使用
    ExecutorService pool = Executors.newFixedThreadPool(2);
    Thread t1 = new MyThread();
    Thread t2 = new MyThread();
    pool.execute(t1); 
    pool.execute(t2);
    pool.shutdown(); 

ThreadPoolExecutor详解
    构造方法
        ThreadPoolExecutor
        int corePoolSize, 池中所保存的线程数，包括空闲线程
        int maximumPoolSize, 池中允许的最大线程数
        long keepAliveTime, 当线程数大于核心时，终止空闲线程等待的最长时间
        TimeUnit unit, 参数的时间单位
        BlockingQueue<Runnable> workQueue, 用于保持runnable任务的队列
        ThreadFactory threadFactory, 线程创建工厂
        RejectedExecutionHandler handler 拒绝策略
    原理
        1.运行的线程少于corePoolSize，任务不会存放到队列，Executor会添加新的线程，直接运行任务
        2.运行的线程等于或多于corePoolSize，Executor会将请求加入队列，而不添加新的线程。
        3.如果无法将请求加入队列且运行的线程数未超过最大线程数，则创建新的线程，否则任务将被拒绝。
    BlockingQueue
        SynchronousQueue：直接提交
        LinkedBlockingQueue：无界队列
        ArrayBlockingQueue：有界队列
    RejectedExecutionHandler
        CallerRunsPolicy 使用execute的线程本身执行
        AbortPolicy 抛出异常
        DiscardPolicy 删除不能执行的任务
        DiscardOldestPolicy 删除队列头部任务


线程池的使用
1.类型选择，线程执行的任务，以及任务数量大小
    计算型任务 等待型任务 
2.线程数量
    线程池的最佳大小取决于可用处理器的数目以及工作队列中的任务的性质。
    若在一个具有 N 个处理器的系统上只有一个工作队列，其中全部是计算性质的任务，
    在线程池具有 N 或 N+1 个线程时一般会获得最大的 CPU 利用率。
    对于那些可能需要等待 I/O 完成的任务（例如，从套接字读取 HTTP 请求的任务），需要让池的大小超过可用处理器的数目，因为并不是所有线程都一直在工作。通过使用概要分析，您可以估计某个典型请求的等待时间（WT）与服务时间（ST）之间的比例。如果我们将这一比例称之为 WT/ST，那么对于一个具有 N 个处理器的系统，需要设置大约 N*(1+WT/ST) 个线程来保持处理器得到充分利用
3.线程增加引起的系统资源限制
    内存，文件句柄，数据库连接等
================================应用
1.任务多，耗时小，引入多线程
2.线程的数量无法控制，以及线程创建销毁耗性能，引入线程池
3.线程本身消耗内存以及线程切换的损耗，需要控制数据
4.根据业务场景选择不同类型的线程池
5.线程逻辑中若需要操作公共资源，引入锁，若是集群部署，则引入分布式锁

秒杀案例
1.redis watch 事务
https://www.cnblogs.com/longtaosoft/p/6627568.html
http://blog.csdn.net/xiaozhushowtime/article/details/72628070
2.数据库insert update事务
http://blog.csdn.net/yd201430320529/article/details/70544203
https://www.zhihu.com/question/54895548